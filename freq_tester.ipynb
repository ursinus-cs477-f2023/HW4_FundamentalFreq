{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161750ff",
   "metadata": {},
   "source": [
    "# Fundamental Frequency Tracking Tester\n",
    "\n",
    "You can feel free to use this file, or you can make a python file to test things, or even put your tests at the bottom of freq.py.  In the case that you use .py files instead of this notebook, save the audio results with the method save_audio in audiotools.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from audiotools import *\n",
    "from effects import *\n",
    "from freq import *\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1f8ca",
   "metadata": {},
   "source": [
    "### Compute and plot YIN frequency observations on a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_audio, sr = load_audio(\"cher.wav\")\n",
    "frame_length = 4096\n",
    "win_length = frame_length//2\n",
    "hop_length = frame_length//4\n",
    "all_freqs = get_yin_freqs(x_audio, frame_length, sr)\n",
    "freqs = pyin_freqs(all_freqs)\n",
    "y = sonify_pure_tone(x_audio, freqs, frame_length//4, sr)\n",
    "ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"cher.wav\"\n",
    "x_audio, sr = load_audio(filename)\n",
    "\n",
    "frame_length = 4096\n",
    "win_length = frame_length//2\n",
    "hop_length = frame_length//4\n",
    "\n",
    "all_freqs = get_yin_freqs(x_audio, frame_length, sr)\n",
    "\n",
    "\n",
    "X = []\n",
    "for t, freqs_t in enumerate(all_freqs):\n",
    "    for (f, thresh) in freqs_t:\n",
    "        X.append([t, f, thresh])\n",
    "X = np.array(X)\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(X[:, 0]*hop_length/sr, X[:, 1], s=10, c=X[:, 2], cmap='magma')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Time (Seconds)\")\n",
    "plt.ylabel(\"Frequency (hz)\")\n",
    "plt.title(filename + \" Yin Frequency Estimates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa9018",
   "metadata": {},
   "source": [
    "### Compute and sonify the results of naive \"greedy observation\" fundamental frequency estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b99a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_naive = naive_freqs(all_freqs)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.scatter(np.arange(freqs_naive.size)*hop_length/sr, freqs_naive, s=10)\n",
    "y = sonify_pure_tone(x_audio, freqs_naive, frame_length//4, sr)\n",
    "plt.xlabel(\"Time (Sec)\")\n",
    "plt.ylabel(\"Frequency (hz)\")\n",
    "save_audio(y, sr, \"marvin_greedy.wav\")\n",
    "plt.title(\"cher.wav Greedy Estimate\")\n",
    "ipd.Audio(sonify_pure_tone(x_audio, freqs, frame_length//4, sr), rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb5d60",
   "metadata": {},
   "source": [
    "### Compute, plot, and sonify the results of HMM-based \"pyin\" fundamental frequency estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a47e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = pyin_freqs(all_freqs)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.scatter(np.arange(freqs.size)*hop_length/sr, freqs, s=10)\n",
    "plt.scatter(np.arange(freqs.size)*hop_length/sr, freqs_naive, s=20, marker='x', zorder=0)\n",
    "plt.ylim([100, 1000])\n",
    "plt.legend([\"pYIN\", \"Greedy Naive\"])\n",
    "plt.xlabel(\"Time (Seconds)\")\n",
    "plt.ylabel(\"Frequency (hz)\")\n",
    "plt.title(\"Frequency Estimates for greedy and pYIN Techniques on cher.wav\")\n",
    "\n",
    "ipd.Audio(sonify_pure_tone(x_audio, freqs, frame_length//4, sr), rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a98a04b",
   "metadata": {},
   "source": [
    "### Do a wiggly autotune example on Cher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d1800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_notes = get_scale(\"G Flat\", major=True)\n",
    "notes, y_auto = autotune(x_audio, freqs, hop_length, allowed_notes, wiggle_amt=1)\n",
    "ipd.Audio(y_auto, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492881d",
   "metadata": {},
   "source": [
    "### Do FM synthesis to make Cher sound like a trumpet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fm = fm_synth(x_audio, freqs, frame_length//4, sr, ratio=2, I=16)\n",
    "save_audio(y_fm, sr, \"cher_bell.wav\")\n",
    "ipd.Audio(y_fm, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f9680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
